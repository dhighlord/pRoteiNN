{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhighlord/proteiNN/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmd1iyrebXc6",
        "colab_type": "code",
        "outputId": "93fe4334-2ab8-48bc-f041-94d5be410bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7823
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "prop = {1:[1.8,-0.17,0.11,0,0.38,-0.21,-1.6,0.42,-0.27,1.12,0.61],\n",
        "18:[-4.5,-0.81,2.58,3.71,-2.57,2.11,12.3,-1.56,1.87,-2.55,0.6],\n",
        "14:[-3.5,-0.42,2.05,3.47,-1.62,0.96,4.8,-1.03,0.81,-0.83,0.06],\n",
        "4:[-3.5,-1.23,3.49,2.95,-3.27,1.36,9.2,-0.51,0.81,-0.83,0.46],\n",
        "3:[2.5,0.24,-0.13,0.49,-0.3,-6.04,-2,0.84,-1.05,0.59,1.07],\n",
        "17:[-3.5,-0.58,2.36,3.01,-1.84,1.52,4.1,-0.96,1.1,-0.78,0],\n",
        "5:[-3.5,-2.02,2.68,1.64,-2.9,2.3,8.2,-0.37,1.17,-0.92,0.47],\n",
        "7:[-0.4,-0.01,0.74,1.72,-0.19,0,-1,0,-0.16,1.2,0.07],\n",
        "8:[-3.2,-0.96,2.06,4.76,-1.44,-1.23,3,-2.28,0.28,-0.93,0.61],\n",
        "9:[4.5,0.31,-0.6,-1.56,1.97,-4.81,-3.1,1.81,-0.77,1.16,2.22],\n",
        "12:[3.8,0.56,-0.55,-1.81,1.82,-4.68,-2.8,1.8,-1.1,1.18,1.53],\n",
        "11:[-3.9,-0.99,2.71,5.39,-3.46,3.88,8.8,-2.03,1.7,-0.8,1.15],\n",
        "13:[1.9,0.23,-0.1,-0.76,1.4,-3.66,-3.4,1.18,-0.73,0.55,1.18],\n",
        "6:[2.8,1.13,-0.32,-2.2,1.98,-4.65,-3.7,1.74,-1.43,0.67,2.02],\n",
        "16:[-1.6,-0.45,2.23,-1.52,-1.44,0.75,0.2,0.86,-0.75,0.54,1.95],\n",
        "19:[-0.8,-0.13,0.84,1.83,-0.53,1.74,-0.6,-0.64,0.42,-0.05,0.05],\n",
        "20:[-0.7,-0.14,0.52,1.78,-0.32,0.78,-1.2,-0.26,0.63,-0.02,0.05],\n",
        "23:[-0.9,1.85,0.3,-0.38,1.53,-3.32,-1.9,1.46,-1.57,-0.19,2.65],\n",
        "25:[-1.3,0.94,0.68,-1.09,0.49,-1.01,0.7,0.51,-0.56,-0.23,1.88],\n",
        "22:[4.2,-0.07,-0.31,-0.78,1.46,-3.5,-2.6,1.34,-0.4,1.13,1.32],\n",
        "26:[0,0,0,0,0,0,0,0,0,0,0]}\n",
        "\n",
        "df_train=np.asarray(pd.read_csv(\"https://raw.githubusercontent.com/dhighlord/proteiNN/master/train.csv\",header=None))\n",
        "df_test=np.asarray(pd.read_csv(\"https://raw.githubusercontent.com/dhighlord/proteiNN/master/test.csv\",header=None))\n",
        "\n",
        "x_train = df_train[:,0]\n",
        "y_train = df_train[:,1]\n",
        "\n",
        "x_test = df_test[:,0]\n",
        "y_test = df_test[:,1]\n",
        "\n",
        "max_len=400\n",
        "\n",
        "###########################################\n",
        "n = x_train\n",
        "j=-1\n",
        "\n",
        "for i in x_train:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "\n",
        "x_train = n\n",
        "###########################################\n",
        "n = y_train\n",
        "j=-1\n",
        "\n",
        "for i in y_train:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "    \n",
        "y_train = n\n",
        "###########################################\n",
        "n = x_test\n",
        "j=-1\n",
        "\n",
        "for i in x_test:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "\n",
        "x_test = n\n",
        "###########################################\n",
        "n = y_test\n",
        "j=-1\n",
        "\n",
        "for i in y_test:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "\n",
        "y_test = n\n",
        "###########################################\n",
        "\n",
        "\n",
        "max_len = max([len(i) for i in x_train])\n",
        "print(max_len)\n",
        "\n",
        "max_len = max([len(i) for i in y_test])\n",
        "print(max_len)\n",
        "\n",
        "#==============   Properties Encoded  ==========================================\n",
        "\n",
        "s = list(x_train[0:3])\n",
        "\n",
        "#for item in range(len(s)):\n",
        "  #s[item]=list(s[item])\n",
        "  \n",
        "#print(s)\n",
        "\n",
        "k = []\n",
        "\n",
        "for i in range(len(s)):\n",
        "  t=[]\n",
        "  for item in range(len(s[i])):\n",
        "    t.append(prop[ord(s[i][item])-64])\n",
        "  k.append(t)\n",
        "#print(\"S -> \", s)\n",
        "#print(\"K -> \", k)\n",
        "\n",
        "#print(k[0])\n",
        "#print(k[1])\n",
        "\n",
        "x_train = np.array(k)#.reshape(2,3,26,1)\n",
        "\n",
        "#==============   ONE_HOT   ====================================================\n",
        "\n",
        "y_train = y_train[0:3]\n",
        "\n",
        "alphabet = 'CEHXZ'\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
        "\n",
        "k = []\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  integer_encoded = [char_to_int[char] for char in y_train[i]]\n",
        "  \n",
        "  onehot_encoded=list()\n",
        "  for value in integer_encoded:\n",
        "\t  letter = [0 for _ in range(len(alphabet))]\n",
        "\t  letter[value] = 1\n",
        "\t  onehot_encoded.append(letter)\n",
        "  \n",
        "  k.append(onehot_encoded)  \n",
        "\n",
        "y_train = np.array(k)#.reshape(2,3,26,1)\n",
        "display(y_train)\n",
        "\n",
        "#==============   ONE_HOT_INVERSION   ====================================================\n",
        " \n",
        "for i in range(len(y_train[0])):\n",
        "  inverted = int_to_char[argmax(y_train[0][i])]\n",
        "  print(inverted)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n",
            "400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[[1, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 1]],\n",
              "\n",
              "       [[1, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 1]],\n",
              "\n",
              "       [[0, 0, 0, 1, 0],\n",
              "        [0, 0, 0, 1, 0],\n",
              "        [0, 0, 0, 1, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 1]]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "C\n",
            "C\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "X\n",
            "X\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "E\n",
            "E\n",
            "E\n",
            "E\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "E\n",
            "E\n",
            "E\n",
            "E\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "C\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "C\n",
            "E\n",
            "E\n",
            "C\n",
            "C\n",
            "E\n",
            "E\n",
            "C\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "X\n",
            "X\n",
            "X\n",
            "X\n",
            "X\n",
            "C\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n",
            "Z\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}